---
title: "Linear regression"
output:
  html_document: default
---

```{r, echo=FALSE}
library(pacman,scales)
p_load(dplyr, ggplot2)
```
#### Create linear regression model
We want to predict personal income (PINCP) using these data :

* age `AGEP`
* sex `SEX`
* class of worker `COW`
* level of education `SCHL`

###Load data
```{r}
load('psub.RData')
```

### Incomes density
This will help us have a better visualization of our data set.
```{r}
ggplot(psub) + 
  geom_density(aes(x = PINCP)) +
  scale_x_continuous(labels=scales::dollar)
```

### Creation of 2 population
A train population (70% of the dataset) and a test population (30% of the dataset).
The goal of the train population is to create the model, we will create the model using the train population data. We will test the model on the test population, to be sure that the model works.

We want to be sure that psub.train and psub.test doesn't contain same data at all
```{r}
psub.train <- psub%>%sample_frac(0.70, replace = FALSE)
psub.test <- setdiff(psub, psub.train)
```

### Next, we determine the model that is best suited for our dataset
The variable we want to predict is PINCP, to define the best suited model for our data set we need to find the best combination of its attributes for predicting.
Therefore we chose to apply the forward selection method to find the most significant ones. For that we need a minimum and a maximum sized model.

We start with only AGEP for our minimum model as we saw it was a significant attribute during our very early tests.
```{r}
min.model = lm(PINCP ~ AGEP, data=psub.train)
```

The most complex model we can have is composed of every combination of attributes
```{r}
biggest <- formula(lm(PINCP~SEX*AGEP*COW*SCHL,psub.train))
```

We create the model using the forward method, beginning by min.model
```{r}
fwd.model = step(min.model, direction='forward', scope=biggest)
```

```{r}
fwd.model
```



